**Задача:**
выделить замкнутые структурные ловушки по структурной карте глубин кровли геологического пласта, структурная ловушка - это закрашенная часть карты по последней замкнутой изолинии, выше которой на карте существует замкнутая возвышенность.


**Данные:**
* X:
    1. rgb: структурная карта глубины кровли геологического пласта, раскрашенная в цветовую палитру от синего (самые низкие части карты) до красного (самые высокие части карты) без изолиний + коричневые толстые разломы.
        - Показать модели рельеф.
        - Мин и макс цветовой шкалы локальные для каждой карты. 
        - Формат png
    2. fault_mask: карта разломов - черный цвет это разломы, белый цвет это все остальное. 
        - Показать модели, где разломы - дополнительная сущность на карте, влияющая на рельеф.
        - Формат png
    3. depth_norm: структурная карта глубины кровли геологического пласта без изолиний и без разломов в черно-белой палитре (черный цвет (0) - наивысшие точки на карте, белый цвет (255) - самые низкие точки на карте) 
        - Показать модели, какая часть более глубокая, а какая наименее глубокая не в 3 измерениях, как в rgb, а в 1 измерении, как в черно-белой палитре. 
        - Мин и макс черно-белой шкалы локальные для каждой карты. 
        - Пустоты под разломами заполнять интерполяцией с помощью cv2.inpaint или scipy.interpolate.griddata.
        - Формат png
* Y:
    1. Карта выделенных замкнутых структурных ловушек, где черный цвет - сами ловушки, белый цвет  - все остальное. 
        - Формат png
* Вспомогательные маски для управления обучения:
    1. depth_mask: маска для depth_norm, где черный цвет - это границы карта без разломов, а белый цвет - это пустоты под разломами. 
        - В черно-белой структурной карте без изолиний и разломов depth_norm, потому что под разломами фактически нет карты, т.к. разломы в основном сбросы (normal faults), т.е. они "раздвигают" кровлю пласта, под ними будут белые пятна - зияние.
        - Чтобы не учитывать обучение на месте пустот под разломами, будем учитывать маску depth_mask в дообучении, чтобы пустоты не учитывались в дообучении.
        - Формат png
    2. map_mask: маска, где черный цвет - это сама карта, белый цвет - это фон за пределами карт + паддинг
        - Нужно, чтобы использовать masked padding / ignore padding и игнорировать паддинг за пределами границ карты при дообучении и инференсе, потому что: 
            - границы карт не являются квадтрадными или прямугольными - это скорее набор прямоугольников разного размера.
            - стандартные стратегии паддинга, такие как reflect и constant, не подходят - они изменяют геологию и создают несуществующие и нереальные структуры.
        - Формат png
* Размер изображений у всех один: 505 (ширина) x 1218 (высота)
* Т.к. исходные карты не имеют прямоугольную или квадратную форму, то на прямоугольной карте будут белые прямоугольники - фон за пределами карты, с ними будем бороться с помощью masked padding.
* Карты на входе - это куски одной большой карты, иногда будут пересечения между кусками.
* Всего карт будет 200-300.
* Паддинг ширины 505 до 512, высоты 1218 до 1248, учесть дополнительный паддинг в map_mask
* Аугментации: horizontal/vertical flip, rotation 90°/180°/270°,  slight brightness/contrast (RGB), небольшая гауссова шумовая добавка
* 20 карт для валидационного сета.
* Карты из одной исходной карты все вместе либо в трейне, либо в валидации.
* Добавить мета-файл (JSON) с source_big_map_id, tile_coords, min/max используемыми для нормализации, чтобы легко объединять и контролировать leakage?


**Обучение модели:**
* Fine-tuning U-Net++с предобученными весами (ResNet34 энкодер, декодер случайно инициализированный), чтобы по X выдавать маску с ловушками Y.
* Для ResNet34 меняем in_channels = 5 (rgb + fault_mask + depth_norm).
* BCE + Dice loss, в который интегрируем маски depth_mask и map_mask.
* Сначала overfit на 1–2 картах (без валидации). Если не получается — проблема в данных/пайплайне.
* Сохранить модель с лучшим Dice на валидации, использовать раннюю остановку.
* Если только маленький батч влезает в память - использовать gradient accumulation.
* Дообучение в бесплатном google colab.


**Стартовые гиперпараметры модели:**
- optimizer: AdamW
- lr: 1e-4 или Differential Learning Rate: Encoder (предобученный) 1e-5, Decoder (новый) 1e-4
- weight_decay: 1e-4
- batch_size: 4–8
- epochs: 80-100
- scheduler: ReduceLROnPlateau (patience 8–10) или CosineAnnealingWarmRestarts


**Метрики:**
* Визуальная оценка
* Dice (ориентир > 0.7-0.8)
* IoU (ориентир > 0.55-0.65)
* Recall (ориентир > 0.75-0.85)
* FP area/FN area (ориентир < 0.3-0.5)

**Инференс, если карты будут больше:**
* Sliding window + overlap + усреднение вероятностей


**Начальные эксперименты:**
1. RGB без изолиний + fault_mask + map_mask
2. RGB без изолиний + fault_mask + depth_norm + depth_mask + map_mask
3. depth_norm + fault_mask + depth_mask + map_mask
4. RGB с изолиниями + fault_mask + depth_norm + depth_mask + map_mask


**TODO на следующих этапах:**
* Tversky loss (α=0.7, β=0.3) или Focal loss, если будет много false negative с BCE + Dice.
* Возможно убрать изолинии из RGB, если переобучается на них.
* Возможно убрать изолинии и разломы из RGB, если переобучается на них или ей будут мешать разломы из-за наличия отдельного канала.
* Попробовать карты с разным шагом изолиний.
* Попробовать DeepLabV3+ или HRNet энкодеры.
* Multi-task learning: auxiliary head на contour/boundary, где наивысшая точка, distance-to-crest.