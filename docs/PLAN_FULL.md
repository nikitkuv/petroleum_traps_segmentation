**Задача:**
выделить замкнутые структурные ловушки по структурной карте глубин кровли геологического пласта, структурная ловушка - это закрашенная часть карты по последней замкнутой изолинии, выше которой на карте существует замкнутая возвышенность.


**Данные:**
* X:
    1. rgb: структурная карта глубины кровли геологического пласта, раскрашенная в цветовую палитру от синего (самые низкие части карты) до красного (самые высокие части карты) + черные тонкие изолинии глубин + коричневые толстые разломы.
        - Показать модели рельеф.
        - Мин и макс цветовой шкалы локальные для каждой карты. 
        - Формат png -> нормализация в [0, 1] по всем каналам.
    2. fault_mask: карта разломов - черные разломы, белое - все остальное. 
        - Показать модели, где разломы - дополнительная сущность на карте, влияющая на рельеф.
        - Формат png -> маска 1/0.
    3. depth_norm: структурная карта глубины кровли геологического пласта без изолиний и без разломов в черно-белой палитре (черный 0 - максимальная глубина, белый 255 - минимальная глубина) 
        - Показать модели, какая часть более глубокая, а какая наименее глубокая не в 3 измерениях, как в rgb, а в 1 измерении, как в черно-белой палитре. 
        - Мин и макс черно-белой шкалы локальные для каждой карты. 
        - Пустоты под разломами заполнять интерполяцией с помощью cv2.inpaint или scipy.interpolate.griddata.
        - Формат png -> нормализация в [0, 1].
* Y:
    1. Карта выделенных замкнутых структурных ловушек, где черный цвет (1) - сами ловушки, белый цвет (0) - все остальное. 
        - Формат png -> маска 1/0.
* Вспомогательные маски для управления обучения:
    1. depth_mask: маска для depth_norm, где 1 - это карта, а 0 - это пустоты под разломами. 
        - В черно-белой структурной карте без изолиний и разломов depth_norm, потому что под разломами фактически нет карты, т.к. разломы в основном сбросы (normal faults), т.е. они "раздвигают" кровлю пласта, под ними будут белые пятна - зияние.
        - Чтобы не учитывать обучение на месте пустот под разломами, будем учитывать маску depth_mask в дообучении, чтобы пустоты не учитывались в дообучении.
        - Формат png -> маска 1/0.
    2. map_mask: маска, где 1 - это карта, 0 - это фон за пределами карт + паддинг (можно фон превратить в -1 и в pytorch ignore_index=-1 в лоссе)
        - Нужно, чтобы использовать masked padding / ignore padding и игнорировать паддинг за пределами границ карты при дообучении и инференсе, потому что: 
            - границы карт не являются квадтрадными или прямугольными - это скорее набор прямоугольников разного размера.
            - стандартные стратегии паддинга, такие как reflect и constant, не подходят - они изменяют геологию и создают несуществующие и нереальные структуры.
        - Формат png -> маска 1/0.
* Всего ~ 50-100 обучающих семплов без учета аугментаций.
* Аугментации: horizontal/vertical flip, rotation 90°/180°/270°,  slight brightness/contrast (RGB), небольшая гауссова шумовая добавка
* Карты изначально имеют небольшой белый фон вокруг, который будет обрезан.
* 10-15 карт для валидационного сета.


**Обучение модели:**
* Fine-tuning U-Net++с предобученными весами (ResNet34 энкодер, декодер случайно инициализированный), чтобы по X выдавать маску с ловушками Y.
* Карты разного размера: есть 714 x 704, есть 655 x 407, есть другого размера, поэтому планируется использовать padding-based дообучение с overlap и весовой склейкой на инференсе.
* Параметры для patch-based дообучения: patch_size = 256x256 (512x512, если потянет железо) , stride = 96 (overlap ~ 62%) (Overlap = patch_size − stride).
* Для ResNet34 меняем in_channels = 5 (rgb + fault_mask + depth_norm). Для каналов 0,1,2 (RGB) — скопировать веса из предобученной ResNet. Для каналов 3,4 (Faults, Depth) — инициализировать, например, средним значением весов RGB каналов или использовать Kaiming initialization.
* BCE + Dice loss, в который интегрируем маски depth_mask и map_mask, маски добавляются ПОСЛЕ вычисления лосса.
* Сначала overfit на 1–2 картах (без валидации). Если не получается — проблема в данных/пайплайне.
* Дообучение в бесплатном google colab.


**Стартовые гиперпараметры модели:**
- optimizer: AdamW
- lr: 1e-4 или Differential Learning Rate: Encoder (предобученный) 1e-5, Decoder (новый) 1e-4 или 1e-3
- weight_decay: 1e-4
- batch_size: 4–8 для 256², 2-4 для 512²
- epochs: 80
- scheduler: ReduceLROnPlateau (patience 8–10)


**Метрики:**
* Визуальная оценка
* Dice (ориентир > 0.7-0.8)
* IoU (ориентир > 0.55-0.65)
* Recall (ориентир > 0.75-0.85)
* FP area/FN area (ориентир < 0.3-0.5)


**Инференс:**
* Weighted blending + Hanning / Gaussian окно, где центр патча вес = 1, на краях стремится к 0, т.е. prediction*weighted_map
* Фреймворк monai и TiledInference
* Stride = 64


**Начальные эксперименты:**
1. X только RGB + map_mask
2. X только depth_norm + 2 маски
3. Все 5 каналов + 2 маски


**TODO на следующих этапах:**
* Stride = 128 (overlap 50%) - если 96 не влезает по железу, или 64 (75%) - если влезает по железу.
* Tversky loss (α=0.7, β=0.3) или Focal loss, если будет много false negative с BCE + Dice.
* Возможно убрать изолинии из RGB, если переобучается на них.
* Попробовать DeepLabV3+ или HRNet энкодеры.
* Multi-task learning: auxiliary head на contour/boundary, где наивысшая точка, distance-to-crest.