from torch.utils.data import DataLoader

from settings import settings
from dataset import GeologyTrapsDataset
from visualization import visualize_dataset_sample


if __name__ == "__main__":
    # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    settings.create_dirs()
    
    file_list = [
        '001_x_faults_H150.png', '001_x_structuralBlackWhite_H150.png',
        '001_x_structuralNOisoline_H150.png', '001_y_traps_H150.png',
        '002_x_faults_H150.png', '002_x_structuralBlackWhite_H150.png',
        '002_x_structuralNOisoline_H150.png', '002_y_traps_H150.png',
        '003_x_faults_H150.png', '003_x_structuralBlackWhite_H150.png',
        '003_x_structuralNOisoline_H150.png', '003_y_traps_H150.png'
    ]
    
    print("="*60)
    print("Testing GeologyTrapsDataset with Visualization")
    print("="*60)
    print(f"\nüìÅ Settings:")
    print(f"  DATA_DIR:       {settings.DATA_DIR}")
    print(f"  TARGET_SIZE:    {settings.TARGET_HEIGHT}√ó{settings.TARGET_WIDTH}")
    print(f"  BATCH_SIZE:     {settings.BATCH_SIZE}")
    print(f"  NUM_WORKERS:    {settings.NUM_WORKERS}")
    print(f"  AUGMENT_PROB:   {settings.AUGMENT_PROB}")
    print(f"  DEVICE:         {settings.DEVICE}")
    print("="*60)
    
    # –°–æ–∑–¥–∞—ë–º Dataset (—Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è–º–∏)
    train_dataset = GeologyTrapsDataset(file_list, data_dir=settings.DATA_DIR, augment=False)
    
    # –°–æ–∑–¥–∞—ë–º Dataset (–±–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)
    val_dataset = GeologyTrapsDataset(file_list, data_dir=settings.DATA_DIR, augment=False)
    
    # 1. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è–º–∏ (train)
    print("\nüìä Visualizing TRAIN sample (with augmentations)...")
    visualize_dataset_sample(train_dataset, idx=0, save_path=str(settings.logs_path / 'viz_train_sample.png'))
    
    # 2. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –±–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π (val)
    print("\nüìä Visualizing VAL sample (without augmentations)...")
    visualize_dataset_sample(val_dataset, idx=0, save_path=str(settings.logs_path / 'viz_val_sample.png'))
    
    print("\nüìä Testing DataLoader...")
    train_loader = DataLoader(
        train_dataset,
        batch_size=settings.BATCH_SIZE,
        shuffle=True,
        num_workers=settings.NUM_WORKERS,
        pin_memory=True
    )
    
    batch = next(iter(train_loader))
    print(f"\n‚úì Batch Input Shape:  {batch['x'].shape}")
    print(f"‚úì Batch Target Shape: {batch['y'].shape}")
    print(f"‚úì Batch Size: {batch['x'].shape[0]}")
    
    print("\n‚úì All tests completed successfully!")
    print("‚úì Ready for UNet++ training!")